{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b005753",
   "metadata": {},
   "source": [
    "#  Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8f77d",
   "metadata": {},
   "source": [
    "## Part I. Exploratory data analysis (correlation analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38150db",
   "metadata": {},
   "source": [
    "### Check the data quality first and perform data preparation tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1035dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#regression packages\n",
    "import sklearn.linear_model as lm\n",
    "\n",
    "#model validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "#f_regression (feature selection)\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# recursive feature selection (feature selection)\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283329ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load and display the data\n",
    "df = pd.read_csv(\"movie_metadata.csv\")\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cdebd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check column names and number of unique values\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c63d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# identify categorical and convert into numerical\n",
    "# create dummy variables or colummn for color\n",
    "df = pd.get_dummies(df, columns=['color'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f7716",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check data types & missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ce7f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the number of missing values for each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4c0f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#handling missing value: \n",
    "#remove the rows with any missing value\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf730872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "mask = df.duplicated(keep=False)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467dbe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display those duplicate rows for review\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55270b20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# find out how many \n",
    "len(df[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac73443",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now drop those duplicated\n",
    "dfnew = df.drop_duplicates(keep=\"first\")\n",
    "dfnew.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f6471",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove unnecessary columns（movie_title，director_name，actor_1_name，actor_2_name，actor_3_name，plot_keywords，country,movie_imdb_link,language,content_rating,title_year, genres）\n",
    "dfnew = dfnew.drop(['movie_title', 'director_name', 'actor_1_name','actor_2_name','actor_3_name','country','plot_keywords','movie_imdb_link','language','content_rating','title_year','genres'], axis=1)\n",
    "dfnew.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb518b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a statistical summay\n",
    "dfnew.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15aa50c",
   "metadata": {},
   "source": [
    "### Perform correlation analysis and discuss the results. What variables are correlated to imdb_score? How are some key variables correlated to each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5089c5b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation analysis\n",
    "dfnew.corr()['imdb_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb0e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation heatmap\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(dfnew.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d89ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# correlation plot(scatter plot)\n",
    "sns.pairplot(dfnew) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081b783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scatter plot for 'gross' and 'imdb_score'\n",
    "dfnew.plot(x=\"gross\", y=\"imdb_score\", kind=\"scatter\", title=\"Relationship between gross and imdb_score\", grid=True, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724637a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scatter plot for 'num_voted_users' and 'imdb_score'\n",
    "dfnew.plot(x=\"num_voted_users\", y=\"imdb_score\", kind=\"scatter\", title=\"Relationship between num_voted_users and imdb_score\", grid=True, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f177fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scatter plot for 'movie_facebook_likes' and 'imdb_score'\n",
    "dfnew.plot(x=\"movie_facebook_likes\", y=\"imdb_score\", kind=\"scatter\", title=\"Relationship between movie_facebook_likes and imdb_score\", grid=True, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbec7b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lmplot for num_voted_users and imdb_score（Plot data and regression model）\n",
    "sns.lmplot(x='num_voted_users', y='imdb_score', data=dfnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b1c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lmplot for duration and imdb_score（Plot data and regression model）\n",
    "sns.lmplot(x='duration', y='imdb_score', data=dfnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95b7b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lmplot for num_critic_for_reviews and imdb_score（Plot data and regression model）\n",
    "sns.lmplot(x='num_critic_for_reviews', y='imdb_score', data=dfnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b3d2e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lmplot for num_user_for_reviews and imdb_score（Plot data and regression model）\n",
    "sns.lmplot(x='num_user_for_reviews', y='imdb_score', data=dfnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d51380",
   "metadata": {},
   "source": [
    "* ***The results of the correlation analysis***\n",
    "\n",
    "* imdb_score has **positive correlation** with num_critic_for_reviews,duration,director_facebook_likes,actor_3_facebook_likes, actor_1_facebook_likes,gross,num_voted_users,cast_total_facebook_likes,num_user_for_reviews,budget,actor_2_facebook_likes,aspect_ratio ,color_black_and_white and movie_facebook_likes\n",
    "* imdb_score has **high positive correlation** with ***_num_voted_users,duration,num_critic_for_reviews and num_user_for_reviews_.***\n",
    "* imdb_score has **negative correlation** with ***_facenumber_in_poster and Color_color_***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7841b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check the correlation between X variables \n",
    "# drop imdb_score  column and only keep the X variables\n",
    "df1=dfnew.drop('imdb_score', axis=1)\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984f65c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the correlation\n",
    "df1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ddf748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlation plot\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(df1.corr(), vmax=.8, square=True,annot=True, fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb716606",
   "metadata": {},
   "source": [
    "***The results of the correlation analysis***\n",
    "\n",
    "* **_num_critic_for_reviews_** has high positive correlation with ***_gross,num_voted_users,num_user_for_reviews and movie_facebook_likes_.***\n",
    "* **_actor_3_facebook_likes_** has high positive correlation with ***_cast_total_facebook_likes,actor_2_facebook_likes_.***\n",
    "* **_actor_1_facebook_likes_** has high positive correlation with ***_cast_total_facebook_likes_.***\n",
    "\n",
    "* **_facenumber_in_poster_** has negative correlation with ***_num_critic_for_reviews_.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a8849",
   "metadata": {},
   "source": [
    "## Part II. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffdfa8",
   "metadata": {},
   "source": [
    "**Normalization the data**\n",
    "* Apply normalizer to our data and run regresssion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d469539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = dfnew['imdb_score'] \n",
    "X = dfnew.drop(['imdb_score'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c7ad2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data is not scaled ... some columns have wide scales\n",
    "plt.boxplot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d430",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa630f8",
   "metadata": {},
   "source": [
    "* **gross and budget** appear to be not good predictors for imdb_score. So let's remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbb439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "y =dfnew['imdb_score']  \n",
    "X =dfnew.drop(['imdb_score','gross','budget'], axis =1)   # remove gross and budget\n",
    "\n",
    "# model building\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "normalizedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce02aef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boxplot ... data is normalized ... all columns are in same scale\n",
    "plt.boxplot(normalizedX);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02310bf",
   "metadata": {},
   "source": [
    "### Build regression models using at least three different regression algorithms, including Lasso. The Y value is imdb_score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3dc6d0",
   "metadata": {},
   "source": [
    "#### Model #1(full model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f67b7",
   "metadata": {},
   "source": [
    "**Model Validation: Split validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c093b6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split validation (70% training & 30% testing data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00376c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's double check \n",
    "\n",
    "print(len(dfnew))\n",
    "print(len(dfnew) * 0.7)        # 70% of the original data\n",
    "print(len(dfnew) * 0.3)        # 30% of the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d85e63",
   "metadata": {},
   "source": [
    "**Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef779b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build full model using all variables\n",
    "model1 = lm.LinearRegression()\n",
    "model1.fit(X_train, y_train)   \n",
    "model1_y = model1.predict(X_test)# generate predicted y for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd43cb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is regression so it has coefficients and y-intercept\n",
    "\n",
    "print('Coefficients: ', model1.coef_)\n",
    "print(\"y-intercept \", model1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c13578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(X.columns, np.transpose(model1.coef_)))).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d11bd",
   "metadata": {},
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd0569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"mean square error: \", mean_squared_error(y_test, model1_y))\n",
    "print(\"variance or r-squared: \", explained_variance_score(y_test, model1_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a96637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplots()\n",
    "plt.scatter(y_test, model1_y)       # showing actual y as X-axis and predicted y as Y-axis\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)   #dotted line represents perfect prediction (actual = predicted)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89e145",
   "metadata": {},
   "source": [
    "* Model 1 doesn't seem to be very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070449f4",
   "metadata": {},
   "source": [
    "#### Model #2(Lasso regression (Regularization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccd6a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "model2 = lm.Lasso(alpha=0.1)\n",
    "model2.fit(X_train, y_train)   \n",
    "model2_y = model2.predict(X_test)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c15fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Coefficients: ', model2.coef_)\n",
    "print(\"y-intercept \", model2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c6a90e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(X.columns, np.transpose(model2.coef_)))).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27fa9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"mean square error: \", mean_squared_error(y_test, model2_y))\n",
    "print(\"variance or r-squared: \", explained_variance_score(y_test, model2_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a534ab5",
   "metadata": {},
   "source": [
    "#### Model #3(f_Regression, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bffe81b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#selec only 2 X variables\n",
    "X_new = SelectKBest(f_regression, k=2).fit_transform(X, y)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909d6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# what are those two columns?\n",
    "selector = SelectKBest(f_regression, k=2).fit(X, y)\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "print(idxs_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee115d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the selected X variables\n",
    "X.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd885d61",
   "metadata": {},
   "source": [
    "f_regression determines that **duration** and **num_voted_users** are two most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5aff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split validation (using X_new)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340bff63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Building\n",
    "\n",
    "model3 = lm.LinearRegression()\n",
    "model3.fit(X_train, y_train)\n",
    "model3_y = model3.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"mean square error: \", mean_squared_error(y_test, model3_y))\n",
    "print(\"variance or r-squared: \", explained_variance_score(y_test, model3_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfa58c",
   "metadata": {},
   "source": [
    "#### Model #4(f_Regression, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34419392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_newer = SelectKBest(f_regression, k=3).fit_transform(X, y)\n",
    "X_newer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c5912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# what are those three columns?\n",
    "\n",
    "selector = SelectKBest(f_regression, k=3).fit(X, y)\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "print(idxs_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbd49af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the selected X variables\n",
    "X.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e770095",
   "metadata": {},
   "source": [
    "f_regression determines that **'num_critic_for_reviews', 'duration', 'num_voted_users'** are three most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d22e091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split validation (using X_new)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_newer, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85addb7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Building\n",
    "model4 = lm.LinearRegression()\n",
    "model4.fit(X_train, y_train)\n",
    "model4_y = model4.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"mean square error: \", mean_squared_error(y_test, model4_y))\n",
    "print(\"variance or r-squared: \", explained_variance_score(y_test, model4_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bda191",
   "metadata": {},
   "source": [
    "#### Model #5(Recursive Feature Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afbb40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = lm.LinearRegression()\n",
    "rfe = RFE(lr, n_features_to_select=2)\n",
    "rfe_y = rfe.fit(X,y)\n",
    "\n",
    "print(\"Features sorted by their rank:\")\n",
    "print(sorted(zip([x for x in rfe.ranking_], X.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb79127",
   "metadata": {},
   "source": [
    "RFE determines that **'color_ Black and White''color_Color'** are two most important predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c8bc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose two variables as X (color_ Black and White and color_Color) and develop a multiple linear regression model (model4).\n",
    "y = dfnew['imdb_score'] \n",
    "X = dfnew[['color_ Black and White','color_Color']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b7294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split validation (70% training & 30% testing data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd16b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build a multiple regression model below\n",
    "\n",
    "model5 = lm.LinearRegression()\n",
    "model5.fit(X_train, y_train)   \n",
    "model5_y = model5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccfebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Coefficients: ', model5.coef_)\n",
    "print(\"y-intercept \", model5.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66905aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(X.columns, np.transpose(model5.coef_)))).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1617b8a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "print(\"mean square error: \", mean_squared_error(y_test, model5_y))\n",
    "print(\"variance or r-squared: \", explained_variance_score(y_test, model5_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64854b",
   "metadata": {},
   "source": [
    "### Evaluate the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43177b70",
   "metadata": {},
   "source": [
    "***We build 5 models:***\n",
    "\n",
    "* MODEL 1(full model), with the mean square error **0.7047386578949048** and  the variance or r-squared is **0.35856948126783417**.\n",
    "\n",
    "* MODEL 2:(Lasso regression),with the mean square error **0.7252891444939343** and the variance or r-squared is **0.3398899983208514**.\n",
    "\n",
    "* MODEL 3:（f_Regression, k=2）, with the mean square error **0.7830449512437508** and the variance or r-squared is  **0.287430567797212**.\n",
    "\n",
    "* MODEL 4:(f_Regression, k=3), with the mean square error **0.7777377932878307**, and the variance or r-squared is  **0.292239918741508**.\n",
    "\n",
    "* MODEL 5:(Recursive Feature Selection), with the mean square error **3.6977823246083156e+23** and the variance or r-squared is   **-3.3647108281847255e+23**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f26e1b",
   "metadata": {},
   "source": [
    "### What is your best model? What is the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444e0a7",
   "metadata": {},
   "source": [
    "* The best model is **Lasso model** model with 2 variables(**duration** and **facenumber_in_poster**)\n",
    "* According to the result above, the full model is with smallest MSE and higher r-square, However, it is accurate but too complex due to too many X variables.\n",
    "* Then the No.2 would be Lasso model with 2 X variables(**duration** and **facenumber_in_poster**), they are accurate enough with an r-square of 0.34 and MSE 0.73, and simple and practical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42689c12",
   "metadata": {},
   "source": [
    "## Part III. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057c1673",
   "metadata": {},
   "source": [
    "### The goal is to build a classification model to predict if a movie is good or bad. You need to create a new “categorical” column from imdb_score in order to build classification models. Create the column by “converting” the imdb_score into 2 categories (or classes): “1~5 and 6~10, which represents bad (or 0) and good (or 1) respectively”\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d717a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# convert imdb_score score to good or bad movie (1~5 bad, 6~10 good)\n",
    "# https://stackoverflow.com/questions/43232753/how-to-change-the-values-of-a-column-based-on-two-conditions-in-python\n",
    "\n",
    "dfnew['movie_grade'] = 0 # bad\n",
    "dfnew.loc[df['imdb_score'] > 6,'movie_grade'] = 1 # good\n",
    "dfnew.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83112c8",
   "metadata": {},
   "source": [
    "### Exclude imdb_score in X variables since the column imdb_score is basically same as the newly created binary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd73298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove imdb_score column\n",
    "df2=dfnew.drop('imdb_score', axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885b284",
   "metadata": {},
   "source": [
    "### Not all variables need to be used as X variables, but it is important to include all the relevant variables as X to increase the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25574381",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check data types\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5c9e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove irrelevant columns(duration,facenumber_in_poster,color_ Black and White,color_Color,budget )\n",
    "df2 = df2.drop(['duration','facenumber_in_poster','color_ Black and White','color_Color','budget'], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d87f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# caculate the number of good movies and bad movies\n",
    "ax=df2['movie_grade'].value_counts().plot(kind='bar',rot=45)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d3e41",
   "metadata": {},
   "source": [
    "* As we can see from the chart above, good movies is **2592** and bad movies are **1132**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a6ea2",
   "metadata": {},
   "source": [
    "### It is important that you use at least three different classification algorithms we have learned and evaluate model quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7a870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Classifiers（algorithm for classification）\n",
    "#import decisiontreeclassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#import logisticregression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "#import knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#import randomforest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#for validating your classification model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1659724",
   "metadata": {},
   "source": [
    "#### Model #1 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf853361",
   "metadata": {},
   "source": [
    "##### Model Building & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53008bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# declare X variables and y variable\n",
    "y = df2['movie_grade'] \n",
    "X = df2.drop(['movie_grade'], axis =1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db8775",
   "metadata": {},
   "source": [
    "##### Search for the optimal k value (GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe647c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model by splitting into train and test sets & develop knn model (name it as knn)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "# Initialize knn Classifier() ... name your decision model \"knn\"\n",
    "knn=KNeighborsClassifier()\n",
    "\n",
    "# Train a knn model\n",
    "knn.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c113f16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "params_knn = {'n_neighbors': np.arange(1, 25)}# frind the best k value from 1 to 25\n",
    "\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gs = GridSearchCV(knn, params_knn, cv=5)\n",
    "\n",
    "#fit model to training data\n",
    "knn_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b45da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save best model\n",
    "knn_best = knn_gs.best_estimator_\n",
    "\n",
    "#check best n_neigbors value\n",
    "print(knn_gs.best_score_)\n",
    "print(knn_gs.best_params_)\n",
    "print(knn_gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6dce2",
   "metadata": {},
   "source": [
    "* From the above result, we can see that the **optimal k value should be 21 , so we set our n_neighbors to 21.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a65fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the model by splitting into train and test sets & develop knn model (name it as knn)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize knn Classifier() ... name your decision model \"knn\"\n",
    "knn=KNeighborsClassifier(n_neighbors=21)\n",
    "\n",
    "# Train a knn model\n",
    "knn.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab6e55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "print(metrics.accuracy_score(y_test, knn.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.confusion_matrix(y_test, knn.predict(X_test))) \n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.classification_report(y_test, knn.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.roc_auc_score(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fab4d6",
   "metadata": {},
   "source": [
    "* The knn model is 68.5% accurate. Therefore, we expect that the model will be about **69% accurate** when the model is applied into a real-world situation.The roc_auc_scoreis **0.53**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d04ad",
   "metadata": {},
   "source": [
    "#### Model #2 Logistic regression using Recursive Feature Selection (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafdd8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import decisiontreeclassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from IPython.display import SVG\n",
    "#from graphviz import Source\n",
    "from IPython.display import display\n",
    "#import logisticregression classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "#import knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#for validating your classification model\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#pip install scikit-plot (optional)\n",
    "import scikitplot as skplt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a4926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 5)  #asking five best attributes\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print((rfe.support_))\n",
    "print((rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fd948b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Features sorted by their rank\n",
    "pd.DataFrame({'feature':X.columns, 'importance':rfe.ranking_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a43721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select 5 most significant features only \n",
    "X_logistic = df2[['num_critic_for_reviews', 'actor_1_facebook_likes', 'cast_total_facebook_likes', 'num_user_for_reviews', 'actor_2_facebook_likes']]\n",
    "print(X_logistic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33195d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## develop logistic regression model with X_logistic (only 5 predictors or independent variables)\n",
    "# evaluate the model by splitting into train and test sets and build a logistic regression model\n",
    "# name it as \"lr\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_logistic, y, test_size=0.3, random_state=0)\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=500)#—_iter refers to iteration\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Model evaluation\n",
    "print(metrics.accuracy_score(y_test, lr.predict(X_test)))\n",
    "print(metrics.confusion_matrix(y_test, lr.predict(X_test)))\n",
    "print(metrics.classification_report(y_test, lr.predict(X_test)))\n",
    "print(metrics.roc_auc_score(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d589a",
   "metadata": {},
   "source": [
    "The Logistic regression model is **70.8%** accurate. Therefore, we expect that the model will be about **71%** accurate when the model is applied into a real-world situation.The roc_auc_scoreis **0.52**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65314e",
   "metadata": {},
   "source": [
    "#### Model #3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d4858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=20)    #building 20 decision trees\n",
    "clf=clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e146ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, clf.predict(X_test))) #overall accuracy\n",
    "print(metrics.confusion_matrix(y_test, clf.predict(X_test)))\n",
    "print(metrics.classification_report(y_test, clf.predict(X_test)))\n",
    "print(metrics.roc_auc_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b63e7",
   "metadata": {},
   "source": [
    "* The random forest model is 75.6% accurate. Therefore, we expect that the model will be about **76% accurate** when the model is applied into a real-world situation.The roc_auc_scoreis **0.68**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a826b60",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "#### Model#4 Decision Trees Model by using SelectKbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86848c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_new = SelectKBest(chi2, k=3).fit_transform(X, y)\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447196d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this will help you identify the column indexes (and names)\n",
    "selector = SelectKBest(chi2, k=3).fit(X, y)\n",
    "idxs_selected = selector.get_support(indices=True)\n",
    "print(idxs_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3b1b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#identify the column  names\n",
    "X.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40021d34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build a decision tree model with those three features ... Split validation:train (70%) and test sets (30%)\n",
    "\n",
    "# declare X variables and y variable\n",
    "y = df2['movie_grade'] \n",
    "X_new = df2[['gross', 'num_voted_users','movie_facebook_likes']]\n",
    "X.head()\n",
    "\n",
    "# split validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=0)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# Initialize DecisionTreeClassifier() ... name your decision model \"dt\"\n",
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "# Train a decision tree model\n",
    "dt.fit(X_train, y_train) \n",
    "\n",
    "dt_y = dt.predict(X_test)\n",
    "\n",
    "\n",
    "#Model evaluation\n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "print(metrics.accuracy_score(y_test, dt.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.confusion_matrix(y_test, dt.predict(X_test))) \n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.classification_report(y_test, dt.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.roc_auc_score(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff44907",
   "metadata": {},
   "source": [
    "* The Decision tree model is 74.1% accurate. Therefore, we expect that the model will be about **74% accurate** when the model is applied into a real-world situation.The roc_auc_scoreis **0.65**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7bb5a",
   "metadata": {},
   "source": [
    "#### Model#5 GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97c131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import advanced algorthms\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c6315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# initialize \n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# fit the model\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f8bba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "print(metrics.accuracy_score(y_test, gb.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.confusion_matrix(y_test, gb.predict(X_test))) \n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.classification_report(y_test, gb.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.roc_auc_score(y_test, gb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee63c5",
   "metadata": {},
   "source": [
    "* The GradientBoosting model is 75.8% accurate. Therefore, we expect that the model will be about **76% accurate** when the model is applied into a real-world situation.The roc_auc_scoreis **0.67**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256cf196",
   "metadata": {},
   "source": [
    "#### Model#6 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9a965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize \n",
    "svm = SVC(gamma='auto', probability=True)\n",
    "# fit the model\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b78d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "print(metrics.accuracy_score(y_test, svm.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.confusion_matrix(y_test, svm.predict(X_test))) \n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.classification_report(y_test, svm.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.roc_auc_score(y_test, svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6d8c2",
   "metadata": {},
   "source": [
    "* The Support Vector Machine model is 70.3% accurate. Therefore, we expect that the model will be about **70% accurate** when the model is applied into a real-world situation.The roc_auc_scoreis **0.50**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e15bca",
   "metadata": {},
   "source": [
    "#### Model#7 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d92ddf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn = MLPClassifier(solver='lbfgs', max_iter=500,random_state=0)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a19e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Model evaluation\n",
    "# http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "print(metrics.accuracy_score(y_test, nn.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.confusion_matrix(y_test, nn.predict(X_test))) \n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.classification_report(y_test, nn.predict(X_test)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(metrics.roc_auc_score(y_test, nn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767293d0",
   "metadata": {},
   "source": [
    "* The Neural Network model is 70.2% accurate. Therefore, we expect that the model will be about **70% accurate** when the model is applied into a real-world situation.The roc_auc_scoreis **0.5**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ae00a",
   "metadata": {},
   "source": [
    "### What is your best classification model? What is the model accuracy? True positive rate? False positive rate? What is ROC score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3614c76",
   "metadata": {},
   "source": [
    "* The best classification model is **Random Forest Model**.  \n",
    "* The model accuracy is **76%**.\n",
    "* True positive rate is **0.87**. \n",
    "* False positive rate is **0.5**\n",
    "* The ROC score is **0.68**.\n",
    "\n",
    "•\t679: those good movies, the model correctly classify them as good movies;\n",
    "•\t163: those bad movies, the model incorrectly classify them as good movies,\n",
    "•\t170:those bad movies, the model correctly classify them as bad movies;\n",
    "•\t106: those good movies, the model incorrectly classify them as bad movies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313a50d",
   "metadata": {},
   "source": [
    "## Part IV. Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e0ec3",
   "metadata": {},
   "source": [
    "### Analyze the data using K-means algorithm. Use the Elbow method to determine the optimal K value for Kmeans analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfad4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384b88f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3=dfnew.drop(['movie_grade','color_Color','color_ Black and White'], axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a35a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# variance test\n",
    "df3.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0223273a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalize data \n",
    "\n",
    "X = (df3 - df3.mean()) / (df3.max() - df3.min())\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b77bdb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# variance test again\n",
    "\n",
    "X.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236403b",
   "metadata": {},
   "source": [
    "* From the variance test result we can see that all the variables are in the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9ec44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# determine an optimal value of k using \"Elbow\" method\n",
    "from scipy.spatial.distance import cdist \n",
    "\n",
    "K = list(range(1, 10)) \n",
    "\n",
    "meandistortions = []\n",
    "\n",
    "for k in K: \n",
    "    kmeans = KMeans(n_clusters=k, random_state=1) \n",
    "    kmeans.fit(X) \n",
    "    meandistortions.append(sum(np.min(cdist(X, kmeans.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0]) \n",
    "\n",
    "plt.plot(K, meandistortions, 'bx-') \n",
    "plt.xlabel('k') \n",
    "plt.ylabel('Average distortion') \n",
    "plt.title('Selecting k with the Elbow Method')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9f1c0",
   "metadata": {},
   "source": [
    "* From the chart above, we decide **k=4**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42b11f",
   "metadata": {},
   "source": [
    "#### Clustering analysis (k = 4): Include \"random_state=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1c194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clustering analysis using k-means\n",
    "k_means=KMeans(init='k-means++',n_clusters=4,random_state=0)\n",
    "k_means.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef197e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cluster labels\n",
    "\n",
    "k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e7e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find out cluster centers\n",
    "\n",
    "k_means.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda18df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert cluster lables to dataframe\n",
    "\n",
    "df4 = pd.DataFrame(k_means.labels_, columns = ['cluster'])\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7418623b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# joining two dataframes\n",
    "\n",
    "df3= df3.reset_index(drop=True)# reset_index after dealing with the original data\n",
    "df4= df4.reset_index(drop=True)\n",
    "\n",
    "df5 = df3.join(df4)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af11cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df5.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a13d1b1",
   "metadata": {},
   "source": [
    "### This is exploratory data analysis, and you need to report the movie (or cluster) “profiles” based on clustering analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177d2da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#How many observations are there in each cluster \n",
    "df5.groupby(['cluster']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e8fb6",
   "metadata": {},
   "source": [
    "* In cluster 0 there are **1909** observations, in cluster 1 there are **162** observations, in cluster 2 there are **1100** observations,in cluster 3 there are **553** observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6522dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The mean values of each cluster in terms of different variables\n",
    "df5.groupby(['cluster']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ddcbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df5.groupby(['cluster']).mean().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4821b8",
   "metadata": {},
   "source": [
    "## profiling \n",
    "1. cluster 0: \n",
    "* relatively low **num_critic_for_reviews**, \n",
    "* relatively low **duration**,\n",
    "* relatively low **director_facebook_likes**,\n",
    "* relatively low **actor_3_facebook_likes**,\n",
    "* relatively low **actor_1_facebook_likes**,\n",
    "* relatively low **gross**,\n",
    "* relatively low **num_voted_users**\t,\n",
    "* relatively low **cast_total_facebook_likes**, \n",
    "* relatively low **facenumber_in_poster**,\n",
    "* relatively low **num_user_for_reviews**,\n",
    "* relatively low **budget**,\n",
    "* relatively low **actor_2_facebook_likes**,\n",
    "* relatively low **imdb_score**,\n",
    "* relatively low **aspect_ratio**,\n",
    "* relatively low **movie_facebook_likes**\n",
    "\n",
    "\n",
    "2. cluster 1: \n",
    "* relatively high **num_critic_for_reviews**, \n",
    "* high **duration**,\n",
    "* high **director_facebook_likes**,\n",
    "* relatively high **actor_3_facebook_likes**,\n",
    "* high **actor_1_facebook_likes**,\n",
    "* relatively high **gross**,\n",
    "* relatively high **num_voted_users**,\n",
    "* high **cast_total_facebook_likes**,\n",
    "* low **facenumber_in_poster**,\n",
    "* relatively high **num_user_for_reviews**,\n",
    "* relatively high **budget**,\n",
    "* relatively high **actor_2_facebook_likes**,\n",
    "* high **imdb_score**,\n",
    "* relatively high **aspect_ratio**,\n",
    "* relatively high **movie_facebook_likes**.\n",
    "\n",
    "\n",
    "3. cluster 2: \n",
    "* low **num_critic_for_reviews**,\n",
    "* low **duration**, \n",
    "* low **director_facebook_likes**,\n",
    "* low  **actor_3_facebook_likes**,\n",
    "* low **actor_1_facebook_likes**,\n",
    "* low **gross**, \n",
    "* low **num_voted_users**, \n",
    "* low **cast_total_facebook_likes**,\n",
    "* high **facenumber_in_poster**, \n",
    "* low **num_user_for_reviews**,\n",
    "* low **budget**, \n",
    "* low **actor_2_facebook_likes**,\n",
    "* low **imdb_score**,\n",
    "* low **aspect_ratio**, \n",
    "* low **movie_facebook_likes**.\n",
    "\n",
    "\n",
    "3. cluster 3: \n",
    "* high **num_critic_for_reviews**,\n",
    "* relatively high **duration**, \n",
    "* relatively high **director_facebook_likes**,\n",
    "* high  **actor_3_facebook_likes**,\n",
    "* relatively high **actor_1_facebook_likes**,\n",
    "* high **gross**, \n",
    "* high **num_voted_users**, \n",
    "* relatively high **cast_total_facebook_likes**,\n",
    "* relatively high **facenumber_in_poster**,\n",
    "* high **num_user_for_reviews**,\n",
    "* high **budget**, \n",
    "* high **actor_2_facebook_likes**,\n",
    "* relatively high **imdb_score**,\n",
    "* high **aspect_ratio**, \n",
    "* high **movie_facebook_likes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32036c50",
   "metadata": {},
   "source": [
    "## Part V. Storytelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755f8b1",
   "metadata": {},
   "source": [
    "### At the end, this is what your client is interested in. Develop useful insights from your correlation analysis and machine learning models (regression, classification, and clustering). Write a summery using bulleted lists and/or numbers in markdown cells. If this section is “too thin”, your project will receive a low grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943d64d",
   "metadata": {},
   "source": [
    "* imdb_score has high positive correlation with num_voted_users, duration,num_critic_for_reviews and num_user_for_reviews, which means high num_voted_users,high duration,high num_critic_for_reviews and high num_user_for_reviews, high imdb_score.\n",
    "* imdb_score has negative correlation with facenumber_in_poster and Color_color,which means _low facenumber_in_poster high imdb_score._\n",
    "* High cast_total_facebook_likes, high imdb_score.\n",
    "* High director_facebook_likes, high imdb_score.\n",
    "* High actor_3_facebook_likes, , high imdb_score.\n",
    "* High actor_1_facebook_likes, high imdb_score.\n",
    "* High actor_2_facebook_likes, high imdb_score.\n",
    "* High budget, high imdb_score.\n",
    "* Our best **regression model** indicates that **duration and facenumber_in_poster** play a very important role in the imdb_score. With the increase of the duration, the imdb_score also increases, and with the increase of facenumber_in_poster, the imdb_score decreases. \n",
    "* After building, validating and evaluating multiple **classification models**, we can see that num_critic_for_reviews, director_facebook_likes , actor_3_facebook_likes, actor_1_facebook_likes , gross, num_voted_users, cast_total_facebook_likes , num_user_for_reviews, actor_2_facebook_likes, aspect_ratio, movie_facebook_likes are important variables in predicting whether the movie is good or bad. Using the 11 features, our test result using **random forest** in predicting whether people leave or not is **76% accurate**.\n",
    "* We use K-means algorithm build a **clustering model** and divide the whole dataset into 4 clusters. In cluster 0 there are 1909 observations, in cluster 1 there are 162 observations, in cluster 2 there are 1100 observations, in cluster 3 there are 553 observations.In Cluster 0, the 11 features(num_critic_for_reviews, duration, director_facebook_likes, actor_3_facebook_likes, actor_1_facebook_likes, gross, num_voted_users, cast_total_facebook_likes, facenumber_in_poster, num_user_for_reviews,  budget, actor_2_facebook_likes,  imdb_score, aspect_ratio,  movie_facebook_likes) are all relatively low. In Cluster 2, all features except  facenumber_in_poster are low. Cluster 1 has the highest imdb_score, its features are either high or relatively high, except facenumber_in_poster, which is the lowest. Cluster 3 has the highest gross, its features are either high or relatively high. \n",
    "* From the data, we can say that a good movie don’t need too many faces in a poster.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291.635px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
